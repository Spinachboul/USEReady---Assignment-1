# Contract NER Extraction

A machine learningâ€“driven **Named Entity Recognition (NER)** system for extracting key fields from legal contracts.
No regex, no rules â€” powered by **HuggingFace Transformers** fine-tuned for contract entity extraction.

---

## Features

* Train a **BERT-based token classification model** on annotated contracts
* Extract fields like:

  * Agreement Value
  * Agreement Start Date
  * Agreement End Date
  * Renewal Notice (Days)
  * Party One
  * Party Two
* Evaluate precision, recall, and F1 on held-out test contracts
* Run inference on a single contract (txt, docx, pdf)
* Interactive **Streamlit app** for uploading contracts & visualizing extracted entities

---

## Project Structure

```
contract-ner/
â”‚â”€â”€ app.py                  # Streamlit app
â”‚â”€â”€ train_model.py          # Train HuggingFace NER model
â”‚â”€â”€ evaluate_model.py       # Evaluate model on test set
â”‚â”€â”€ inference.py            # Extract entities from a single document
â”‚â”€â”€ requirements.txt        # Dependencies
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ data_loader.py      # Load docs (txt, pdf, docx)
â”‚   â”œâ”€â”€ metrics.py          # Precision, recall, F1
â”‚   â””â”€â”€ preprocessing.py    # Tokenization, dataset prep (BIO tagging)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv           # Training metadata
â”‚   â”œâ”€â”€ test.csv            # Test metadata
â”‚   â”œâ”€â”€ train/              # Train docs
â”‚   â””â”€â”€ test/               # Test docs
â”‚
â””â”€â”€ contract-ner-model/     # Saved HuggingFace model after training
```

---

## Installation

```bash
git clone https://github.com/yourname/useREADY-Assignment-1.git
cd contract-ner
python -m venv venv
source venv/bin/activate   # (Linux/Mac)
venv\Scripts\activate      # (Windows)

pip install -r requirements.txt
```

---

## Training

Train the model on your dataset:

```bash
python -m train_model.py
```

The trained model will be saved in:

```
contract-ner-model/
```

---

## Evaluation

Evaluate model performance on the test set:

```bash
python -m evaluate_model.py
```

Outputs per-field and overall precision, recall, and F1.

---

## Streamlit App

Launch the interactive app:

```bash
streamlit run app.py
```

Features:

* Upload a contract â†’ Extract fields
* Upload a `test.csv` â†’ View evaluation metrics

## Requirements

* transformers
* datasets
* torch
* scikit-learn
* pandas
* numpy
* streamlit
* python-docx
* PyPDF2

(Installed via `requirements.txt`)

ðŸ‘‰ Do you want me to also add a **usage example screenshot** (Streamlit UI + extracted JSON) to the README for extra clarity?
